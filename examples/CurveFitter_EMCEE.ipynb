{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of MCMC non-linear regression with EMCEE and refnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`refnx` is a package that can be used for non-linear regression (curvefitting). Here I demonstrate how it can be used to analyse Gaussian curve dataset, with Bayesian MCMC sampling of the posterior distributions of the parameters. This is a very robust way of estimating parameter uncertainties. I will also do the analysis with the `emcee` package for comparison\n",
    "\n",
    "The first step is all the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\testenv\\lib\\site-packages\\PIL\\Image.py:81: RuntimeWarning: The _imaging extension was built for another version of Python.\n",
      "  RuntimeWarning\n",
      "C:\\Miniconda3\\envs\\testenv\\lib\\site-packages\\PIL\\Image.py:81: RuntimeWarning: The _imaging extension was built for another version of Python.\n",
      "  RuntimeWarning\n",
      "C:\\Miniconda3\\envs\\testenv\\lib\\site-packages\\PIL\\Image.py:81: RuntimeWarning: The _imaging extension was built for another version of Python.\n",
      "  RuntimeWarning\n",
      "C:\\Miniconda3\\envs\\testenv\\lib\\site-packages\\PIL\\Image.py:81: RuntimeWarning: The _imaging extension was built for another version of Python.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING, Using slow reflectivity calculation\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import emcee\n",
    "import corner\n",
    "from scipy.optimize import leastsq\n",
    "from refnx.analysis import CurveFitter\n",
    "from refnx.dataset import Data1D\n",
    "import refnx.analysis as ra\n",
    "from matplotlib.pyplot import *\n",
    "from lmfit import fit_report\n",
    "%matplotlib inline\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = (10.0, 6.0)\n",
    "matplotlib.pyplot.rcParams['figure.dpi'] = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to load some data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gauss_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d53359ae0c8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gauss_data.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_sd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'.k'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Miniconda3\\envs\\testenv\\lib\\site-packages\\refnx-0.0.5.dev0+527b3cb-py3.4-win-amd64.egg\\refnx\\dataset\\data1d.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# if it's a file then open and load the file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Miniconda3\\envs\\testenv\\lib\\site-packages\\refnx-0.0.5.dev0+527b3cb-py3.4-win-amd64.egg\\refnx\\dataset\\data1d.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mFile\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mfrom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Miniconda3\\envs\\testenv\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'U'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m                 \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gauss_data.txt'"
     ]
    }
   ],
   "source": [
    "data = Data1D('gauss_data.txt')\n",
    "errorbar(data.x, data.y, yerr=data.y_sd, fmt='.k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the fit functions. The first type is what you would use for `refnx.analysis.CurveFitter`, the second is a function that you can use with `emcee`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, p, *args):\n",
    "    p0 = p.valuesdict()\n",
    "    return p0['p0'] + p0['p1'] * np.exp(-((x - p0['p2']) / p0['p3'])**2)\n",
    "\n",
    "def gauss2(x, p, *args):\n",
    "    return p[0] + p[1] * np.exp(-((x - p[2]) / p[3])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up initial parameter guesses and lower and upper bounds. The last step is to create an `lmfit.Parameters` instance for use with CurveFitter. The default parameter names created by `to_parameters` are 'p0', 'p1', ..., 'pn'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p0 = np.array([0.1, 20., 0.1, 0.1])\n",
    "bounds_varying = np.array([(-1, 1), (0, 30), (-5., 5.), (0.001, 2)])\n",
    "params = ra.to_parameters(p0, bounds=bounds_varying)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse with emcee\n",
    "\n",
    "To start with we'll do the analysis with the `emcee` package. Then we'll repeat the analysis with `refnx.analysis.CurveFitter`. \n",
    "\n",
    "The following functions have to be defined for `emcee`. The log-likelihood, the uniform log-prior and the overall log-posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residuals(theta):\n",
    "    resid = (gauss2(data.x, theta) - data.y) / data.y_sd\n",
    "    return resid\n",
    "    \n",
    "def lnlike(theta):\n",
    "    # log likelihood\n",
    "    return -0.5 * (np.sum(residuals(theta) ** 2))\n",
    "\n",
    "def lnprior(theta):\n",
    "    # uniform prior\n",
    "    if (np.any(theta > bounds_varying[:, 1])\n",
    "            or np.any(theta < bounds_varying[:, 0])):\n",
    "        return -np.inf\n",
    "    return 0\n",
    "\n",
    "def lnpost(theta):\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fit the data with least squares first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = leastsq(residuals, p0, full_output=True)\n",
    "best_fit = result[0]\n",
    "best_errors = np.sqrt(np.diag(result[1]))\n",
    "for mean, std in zip(best_fit, best_errors):\n",
    "    print(\"{:<12g} +/-  {:<10g}\".format(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the walkers for `emcee`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndim, nwalkers = 4, 100\n",
    "pos = np.array([p0 * (1 + 1e-2 * np.random.randn(ndim))\n",
    "    for i in range(nwalkers)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `emcee` sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnpost)\n",
    "a = sampler.run_mcmc(pos, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard 100 burn in steps for each walker and flatten the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chain = sampler.chain[:, 100:, :].reshape(-1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse with CurveFitter\n",
    "\n",
    "Now we're going to do the analysis using a `refnx.analysis.CurveFitter` instance, it should be a lot simpler than the direct approach above. First setup the curvefitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini = CurveFitter(gauss, data, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all do a least-squares fit, to get a starting point for the sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_leastsq = mini.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the MCMC sampling with CurveFitter instead. There are 100 walkers, we do 2000 steps on each walker. After the sampling discard the first 100 steps of each walker and take every 5th step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note that we initialise the emcee sampling with the output of the leastsq fit.\n",
    "res_sampling = mini.emcee(nwalkers=100, steps=2000, burn=500, thin=10, params=res_leastsq.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows the posterior distributions for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=corner.corner(res_sampling.flatchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the fits, are they good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pgen(parameters, flatchain, idx=None):\n",
    "    # generator for all the different parameters from a flatchain.\n",
    "    if idx is None:\n",
    "        idx = range(np.size(flatchain, 0))\n",
    "    for i in idx:\n",
    "        vec = flatchain.iloc[i]\n",
    "        for var_name in flatchain.columns:\n",
    "            parameters[var_name].value = flatchain.iloc[i][var_name]\n",
    "        yield parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorbar(data.x, data.y, yerr=data.y_sd, fmt=\".\")\n",
    "for pars in pgen(res_sampling.params,\n",
    "                 res_sampling.flatchain,\n",
    "                 idx=np.random.choice(len(res_sampling.flatchain), size=500, replace=False)):\n",
    "    plot(data.x, gauss(data.x, pars), color=\"k\", alpha=0.05)\n",
    "plot(data.x, gauss(data.x, res_sampling.params), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following fit parameters are obtained. Lets compare them to the least squares output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Curvefitter.emcee\")\n",
    "print(\"-----------------\")\n",
    "print(fit_report(res_sampling.params))\n",
    "\n",
    "print(\"\\nleastsq\")\n",
    "print(\"-------\")\n",
    "print(fit_report(res_leastsq.params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
